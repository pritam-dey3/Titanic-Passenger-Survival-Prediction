{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37164bitdbaebdfaa49a421ea1ce67eb13d278b5",
   "display_name": "Python 3.7.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic data\n",
    "### getting started with kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   PassengerId  Pclass  ... Cabin Embarked\n0            1       3  ...   NaN        S\n1            2       1  ...   C85        C\n2            3       3  ...   NaN        S\n3            4       1  ...  C123        S\n4            5       3  ...   NaN        S\n\n[5 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "data_dir = 'data/'\n",
    "\n",
    "data = pd.read_csv(data_dir + 'train.csv')\n",
    "labels = data['Survived']\n",
    "data = data.drop('Survived', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['drp__Pclass', 'drp__Sex', 'drp__Age', 'drp__SibSp', 'drp__Parch', 'drp__Fare', 'cabin_imp__Cabin', 'Emb_imp__Embarked']\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   0       1   2  3  4        5  6  7\n0  3    male  22  1  0     7.25  Z  S\n1  1  female  38  1  0  71.2833  C  C\n2  3  female  26  0  0    7.925  Z  S\n3  1  female  35  1  0     53.1  C  S\n4  3    male  35  0  0     8.05  Z  S",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>male</td>\n      <td>22</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.25</td>\n      <td>Z</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>female</td>\n      <td>38</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>female</td>\n      <td>26</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.925</td>\n      <td>Z</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>female</td>\n      <td>35</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1</td>\n      <td>C</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>male</td>\n      <td>35</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.05</td>\n      <td>Z</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "print(imputer_1.get_feature_names())\n",
    "pd.DataFrame(X[0:6, :]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(891, 12)\nIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pclass** : ticket class <br>\n",
    "**SibSp** : # sibling or spouse aboard <br>\n",
    "**Parch** : # parents or children aboard <br>\n",
    "**Embark** : Port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(12, 12)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# check the cabin data null values\n",
    "data[(data.Pclass == 3) & (~data.Cabin.isnull())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Age', 'Cabin', 'Embarked']"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# check which columns contain nan values\n",
    "def findNaNCol(data):\n",
    "    nancols = []\n",
    "    for column in data.columns:\n",
    "        if data[column].isnull().any():\n",
    "            nancols.append(column)\n",
    "    return nancols\n",
    "\n",
    "nancols = findNaNCol(data)\n",
    "nancols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Age', 'Fare', 'Cabin']"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# check if test data also contains same columns\n",
    "test_data = pd.read_csv(data_dir + 'test.csv')\n",
    "findNaNCol(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "We need to find ways to impute 'Age' and 'Fare' <br>\n",
    "I dont think 'Embarked' is at all important <br>\n",
    "'Cabin' can be converted into categorical (? maybe? need to check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[3 2 1]\n"
    }
   ],
   "source": [
    "# if there is any Pclass that has non null values of cabin\n",
    "print(data.Pclass[data.Cabin.isnull()].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "unique_cabin : (148,)\ntotal_Cabin_nan : 687\n"
    }
   ],
   "source": [
    "print(f'unique_cabin : {data.Cabin.unique().shape}\\ntotal_Cabin_nan : {sum(data.Cabin.isnull())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note2:\n",
    "After imputing 'Age' and 'Fare', the list of explanatory variables becomes <br>\n",
    "{id, Pclass, sex, age, sibsp, parch, fare, cabin}\n",
    "\n",
    "using sibsp and parch can be tricky, maybe i need to form separate model for those, to provide probability of surviving, when you have extra family member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note3:\n",
    "I think number of siblings or parents/children can defintely tell something about the age group of a person. The remaining variables that make a little to no sense are {Pclass, sex, Fare}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pipelines\n",
    "\n",
    "-- Drop Name, Ticket + add fam_n_frnd ;; Impute, categorize Cabin and Embarked <br>\n",
    "-- One hot encode Cabin, Embarked, Sex, Pclass <br>\n",
    "-- Create ordinal fare group {note that we can only group the data in training set}<br>\n",
    "-- Impute ordinal fare {transformation will be tricky as it contains NaN values}<br>\n",
    "-- impute Age <br>\n",
    "====== thus cleaning is done\n",
    "-- finally fit xgboost, svm and knn and use hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  ohe__x0_1 ohe__x0_2 ohe__x0_3  ... nthn__SibSp nthn__Parch farecut__Fare\n0         0         0         1  ...           1           0             1\n1         1         0         0  ...           1           0             3\n2         0         0         1  ...           0           0             1\n3         1         0         0  ...           1           0             3\n4         0         0         1  ...           0           0             1\n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ohe__x0_1</th>\n      <th>ohe__x0_2</th>\n      <th>ohe__x0_3</th>\n      <th>ohe__x1_female</th>\n      <th>ohe__x1_male</th>\n      <th>ohe__x2_A</th>\n      <th>ohe__x2_B</th>\n      <th>ohe__x2_C</th>\n      <th>ohe__x2_D</th>\n      <th>ohe__x2_E</th>\n      <th>ohe__x2_F</th>\n      <th>ohe__x2_G</th>\n      <th>ohe__x2_T</th>\n      <th>ohe__x2_Z</th>\n      <th>ohe__x3_C</th>\n      <th>ohe__x3_Q</th>\n      <th>ohe__x3_S</th>\n      <th>nthn__Age</th>\n      <th>nthn__SibSp</th>\n      <th>nthn__Parch</th>\n      <th>farecut__Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>22</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>38</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>26</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>35</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>35</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import re\n",
    "\n",
    "class CabinImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, imp='Z'):\n",
    "        self.imp = imp\n",
    "        pat = re.compile(r'^[A-Z]')\n",
    "        self.categorizer = np.vectorize(lambda x: pat.match(x).group())\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.imputer = SimpleImputer(missing_values=np.NaN, strategy='constant', fill_value=self.imp)\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        X = self.imputer.fit_transform(X)\n",
    "        X[:, 0] = self.categorizer(X[:, 0])\n",
    "        return X\n",
    "    def get_feature_names(self):\n",
    "        return np.array(['Cabin'])\n",
    "    def get_params(self, deep=True):\n",
    "        return {'imp': self.imp}\n",
    "\n",
    "class ModeImputer(SimpleImputer):\n",
    "    def get_feature_names(self):\n",
    "        return np.array(['Embarked'])\n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_ix=[0, 2, 7], features=[]):\n",
    "        self.drop_list = drop_ix\n",
    "        self.features = features\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.drops = self.drop_list\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        return np.delete(X, self.drops, axis=1)\n",
    "    def get_feature_names(self):\n",
    "        return np.delete(np.array(self.features), self.drop_list, axis=0)\n",
    "    def get_params(self, deep=True):\n",
    "        return {'drop_ix': self.drop_list, 'features': self.features}\n",
    "\n",
    "class DoNothing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=['Age', 'SibSp', 'Parch']):\n",
    "        self.features = features\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.feature_len = X.shape[1]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "    def get_params(self, deep=True):\n",
    "        return {'features': self.features}\n",
    "    def get_feature_names(self):\n",
    "        return self.features\n",
    "\n",
    "class FareCat(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" This assumes that no value is missing in Fare column \"\"\"\n",
    "    def __init__(self):\n",
    "        self.imputing_model = None\n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = pd.Series(X[:, 0])\n",
    "        X = pd.cut(X, [-1, 0.1, 10, 30, 100, 200, np.inf], labels=np.arange(0, 6))\n",
    "        return np.reshape(X.to_numpy(), (-1, 1))\n",
    "    def get_feature_names(self, deep=True):\n",
    "        return ['Fare']\n",
    "\n",
    "cols = data.columns.drop(['Cabin', 'Embarked'])\n",
    "imputer_1 = ColumnTransformer([\n",
    "    ('drp', DropColumns(drop_ix=[0, 2, 7], features=cols), cols),\n",
    "    ('cabin_imp', CabinImputer(), ['Cabin']),\n",
    "    ('Emb_imp', ModeImputer(strategy='most_frequent'), ['Embarked'])\n",
    "])\n",
    "\n",
    "ohe_categories = [np.array([1, 2, 3], dtype=object),\n",
    "                np.array(['female', 'male'], dtype=object),\n",
    "                np.array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'Z'], dtype=object),\n",
    "                np.array(['C', 'Q', 'S'], dtype=object)]\n",
    "                # had to fit a model and get the categories\n",
    "ohe_cols = [0, 1, 6, 7]\n",
    "nthn_cols = [2, 3, 4]\n",
    "imputer_2 = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(categories=ohe_categories), ohe_cols),\n",
    "    ('nthn', DoNothing(), nthn_cols),\n",
    "    ('farecut', FareCat(), [5])\n",
    "])\n",
    "\n",
    "half_pipeline = Pipeline([\n",
    "    ('imp1', imputer_1),\n",
    "    ('imp2', imputer_2),\n",
    "])\n",
    "\n",
    "X = half_pipeline.fit_transform(data)\n",
    "X = pd.DataFrame(X)\n",
    "X.columns = imputer_2.get_feature_names()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to keep indexing clean as much as possible\n",
    "Pclass_ix = np.s_[:, 0:3]\n",
    "Sex_ix = np.s_[:, 3:5]\n",
    "Cabin_ix = np.s_[:, 5:14]\n",
    "Embarked_ix = np.s_[:, 14:17]\n",
    "Age_ix = np.s_[:, 17]\n",
    "SibSp_ix = np.s_[:, 18]\n",
    "Parch_ix = np.s_[:, 19]\n",
    "Fare_ix = np.s_[:, 20]\n",
    "\n",
    "#create a function to name data frames\n",
    "namedict = {'Pclass': ['1', '2', '3'], \n",
    "            'Sex': ['female', 'male'],\n",
    "            'Cabin': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'Z'],\n",
    "            'Embarked': ['C', 'Q', 'S'],\n",
    "            'Age': '',\n",
    "            'SibSp': '',\n",
    "            'Parch': '',\n",
    "            'Fare': '',\n",
    "            }\n",
    "\n",
    "def col_names(features=[], extra = []):\n",
    "    namelist = []\n",
    "    for feature in features:\n",
    "        for category in namedict[feature]:\n",
    "            namelist.append(feature + '_' + category)\n",
    "    namelist.extend(extra)\n",
    "    return namelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline: (conitinued)\n",
    "Imputing Fare and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing classes for Fare and age\n",
    "class ImputeFare(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.model = XGBClassifier(max_depth=3, max_leaf_nodes=3, n_estimators=30)\n",
    "    def fit(self, X=None, y=None):\n",
    "        y = X[Fare_ix]\n",
    "        nan_ix = np.isnan(y.astype(float))\n",
    "        X = X[~nan_ix]\n",
    "        y = y[~nan_ix]\n",
    "        X = np.c_[X[Pclass_ix], X[Sex_ix], X[Cabin_ix],\n",
    "            X[Embarked_ix], X[SibSp_ix] + X[Parch_ix]]\n",
    "        self.model = self.model.fit(X,y)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        y = X[Fare_ix]\n",
    "        nan_ix = np.isnan(y.astype(float))\n",
    "        #select predictor set\n",
    "        X_pred = np.c_[X[Pclass_ix], X[Sex_ix], X[Cabin_ix],\n",
    "            X[Embarked_ix], X[SibSp_ix] + X[Parch_ix]]\n",
    "        X_pred = X_pred[nan_ix]\n",
    "        #select features\n",
    "        #replace nan variables\n",
    "        X[nan_ix, Fare_ix[1]] = self.model.predict(X_pred)\n",
    "        return X \n",
    "\n",
    "class ImputeAge(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.model = XGBRegressor(max_depth=3, max_leaf_nodes=4, n_estimators=13)\n",
    "    def fit(self, X=None, y=None):\n",
    "        y = X[Age_ix]\n",
    "        nan_ix = np.isnan(y.astype(float))\n",
    "        X = X[~nan_ix]\n",
    "        y = y[~nan_ix]\n",
    "        X = np.c_[X[Pclass_ix], X[SibSp_ix], X[Parch_ix], \n",
    "                X[Sex_ix], X[Fare_ix]]\n",
    "        self.model = self.model.fit(X, y)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        y = X[Age_ix]\n",
    "        nan_ix = np.isnan(y.astype(float))\n",
    "        #select predictor set\n",
    "        X_pred = np.c_[X[Pclass_ix], X[SibSp_ix], X[Parch_ix], \n",
    "                X[Sex_ix], X[Fare_ix]]\n",
    "        X_pred = X_pred[nan_ix]\n",
    "        #replace nan variables\n",
    "        X[nan_ix, Age_ix[1]] = self.model.predict(X_pred)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([22.0, 38.0, 26.0, 35.0, 35.0, 28.847219467163086, 54.0, 2.0, 27.0,\n       14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, 33.31815719604492,\n       31.0, 24.800701141357422, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0,\n       28.847219467163086, 19.0, 24.800701141357422, 28.847219467163086,\n       40.0, 35.076568603515625, 24.800701141357422, 66.0, 28.0, 42.0,\n       28.847219467163086, 21.0, 18.0, 14.0, 40.0, 27.0,\n       28.847219467163086, 3.0, 19.0, 28.847219467163086,\n       25.979949951171875, 24.800701141357422, 24.37738800048828, 18.0,\n       7.0, 21.0, 49.0, 29.0, 65.0, 40.654579162597656, 21.0, 28.5, 5.0,\n       11.0, 22.0, 38.0, 45.0, 4.0, 44.0030517578125, 19.965560913085938,\n       29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0,\n       28.847219467163086, 28.847219467163086, 0.83, 30.0, 22.0, 29.0,\n       24.800701141357422, 28.0, 17.0, 33.0, 16.0, 28.847219467163086,\n       23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, 28.847219467163086, 71.0,\n       23.0, 34.0, 34.0, 28.0, 28.847219467163086, 21.0, 33.0, 37.0, 28.0,\n       21.0, 28.847219467163086, 38.0, 24.503000259399414, 47.0, 14.5,\n       22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0,\n       28.847219467163086, 32.5, 32.5, 54.0, 12.0, 28.847219467163086,\n       24.0, 19.830495834350586, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0,\n       19.0, 37.0, 16.0, 24.0, 19.59815788269043, 22.0, 24.0, 19.0, 18.0,\n       19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5,\n       28.847219467163086, 51.0, 16.0, 30.0, 28.847219467163086,\n       6.937412261962891, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0,\n       38.097286224365234, 45.0, 44.0030517578125, 28.0, 61.0, 4.0, 1.0,\n       21.0, 56.0, 18.0, 6.319512844085693, 50.0, 30.0, 36.0,\n       7.868288516998291, 33.31815719604492, 9.0, 1.0, 4.0,\n       40.654579162597656, 24.503000259399414, 45.0, 40.0, 36.0, 32.0,\n       19.0, 19.0, 3.0, 44.0, 58.0, 28.847219467163086, 42.0,\n       24.800701141357422, 24.0, 28.0, 6.937412261962891, 34.0, 45.5,\n       18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0,\n       27.565866470336914, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0,\n       28.847219467163086, 38.0, 22.0, 19.0, 20.5, 18.0,\n       7.250389099121094, 35.0, 29.0, 59.0, 5.0, 24.0, 24.800701141357422,\n       44.0, 8.0, 19.0, 33.0, 24.503000259399414, 24.503000259399414,\n       29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, 28.847219467163086,\n       29.0, 62.0, 30.0, 41.0, 29.0, 36.38572692871094, 30.0, 35.0, 50.0,\n       28.847219467163086, 3.0, 52.0, 40.0, 24.800701141357422, 36.0,\n       16.0, 25.0, 58.0, 35.0, 40.654579162597656, 25.0, 41.0, 37.0,\n       24.800701141357422, 63.0, 45.0, 33.31815719604492, 7.0, 35.0, 65.0,\n       28.0, 16.0, 19.0, 44.0030517578125, 33.0, 30.0, 22.0, 42.0, 22.0,\n       26.0, 19.0, 36.0, 24.0, 24.0, 44.0030517578125, 23.5, 2.0,\n       40.654579162597656, 50.0, 24.800701141357422, 24.37738800048828,\n       19.0, 31.568952560424805, 28.847219467163086, 0.92, 35.767578125,\n       17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0,\n       31.0, 40.0, 22.0, 27.0, 30.0, 22.0, 6.937412261962891, 36.0, 61.0,\n       36.0, 31.0, 16.0, 23.96637535095215, 45.5, 38.0, 16.0,\n       35.076568603515625, 28.847219467163086, 29.0, 41.0, 45.0, 45.0,\n       2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, 24.503000259399414, 3.0,\n       42.0, 23.0, 40.654579162597656, 15.0, 25.0, 28.847219467163086,\n       28.0, 22.0, 38.0, 24.800701141357422, 24.800701141357422, 40.0,\n       29.0, 45.0, 35.0, 25.979949951171875, 30.0, 60.0,\n       24.800701141357422, 24.800701141357422, 24.0, 25.0, 18.0, 19.0,\n       22.0, 3.0, 36.618064880371094, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0,\n       32.0, 35.0, 28.847219467163086, 18.0, 1.0, 36.0,\n       28.847219467163086, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0,\n       46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0,\n       21.0, 7.250389099121094, 28.847219467163086, 28.847219467163086,\n       33.0, 33.31815719604492, 44.0, 24.800701141357422, 34.0, 18.0,\n       30.0, 10.0, 28.847219467163086, 21.0, 29.0, 28.0, 18.0,\n       28.847219467163086, 28.0, 19.0, 28.847219467163086, 32.0, 28.0,\n       24.503000259399414, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0,\n       45.0, 20.0, 25.0, 28.0, 28.847219467163086, 4.0, 13.0, 34.0, 5.0,\n       52.0, 36.0, 25.979949951171875, 30.0, 49.0, 28.847219467163086,\n       29.0, 65.0, 36.618064880371094, 50.0, 28.847219467163086, 48.0,\n       34.0, 47.0, 48.0, 28.847219467163086, 38.0, 33.31815719604492,\n       56.0, 28.847219467163086, 0.75, 28.847219467163086, 38.0, 33.0,\n       23.0, 22.0, 40.654579162597656, 34.0, 29.0, 22.0, 2.0, 9.0,\n       33.31815719604492, 50.0, 63.0, 25.0, 7.250389099121094, 35.0, 58.0,\n       30.0, 9.0, 25.979949951171875, 21.0, 55.0, 71.0, 21.0,\n       27.261302947998047, 54.0, 27.261302947998047, 25.0, 24.0, 17.0,\n       21.0, 24.800701141357422, 37.0, 16.0, 18.0, 33.0, 44.0030517578125,\n       28.0, 26.0, 29.0, 28.847219467163086, 36.0, 54.0, 24.0, 47.0, 34.0,\n       27.261302947998047, 36.0, 32.0, 30.0, 22.0, 28.847219467163086,\n       44.0, 28.847219467163086, 40.5, 50.0, 36.2702522277832, 39.0, 23.0,\n       2.0, 28.847219467163086, 17.0, 19.59815788269043, 30.0, 7.0, 45.0,\n       30.0, 27.261302947998047, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0,\n       19.0, 33.31815719604492, 33.0, 8.0, 17.0, 27.0, 28.847219467163086,\n       22.0, 22.0, 62.0, 48.0, 36.2702522277832, 39.0, 36.0,\n       28.847219467163086, 40.0, 28.0, 28.847219467163086,\n       24.800701141357422, 24.0, 19.0, 29.0, 28.847219467163086, 32.0,\n       62.0, 53.0, 36.0, 24.800701141357422, 16.0, 19.0, 34.0, 39.0,\n       24.503000259399414, 32.0, 25.0, 39.0, 54.0, 36.0,\n       28.847219467163086, 18.0, 47.0, 60.0, 22.0, 28.847219467163086,\n       35.0, 52.0, 47.0, 20.128196716308594, 37.0, 36.0,\n       28.214365005493164, 49.0, 28.847219467163086, 49.0, 24.0,\n       28.847219467163086, 40.654579162597656, 44.0, 35.0, 36.0, 30.0,\n       27.0, 22.0, 40.0, 39.0, 28.847219467163086, 24.503000259399414,\n       28.847219467163086, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0,\n       20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, 28.847219467163086, 80.0,\n       51.0, 32.0, 39.640010833740234, 9.0, 28.0, 32.0, 31.0, 41.0,\n       25.979949951171875, 20.0, 24.0, 2.0, 25.401071548461914, 0.75,\n       48.0, 19.0, 56.0, 28.847219467163086, 23.0, 28.847219467163086,\n       18.0, 21.0, 24.800701141357422, 18.0, 24.0, 28.847219467163086,\n       32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0,\n       28.847219467163086, 43.0, 36.618064880371094, 40.0, 31.0, 70.0,\n       31.0, 33.31815719604492, 18.0, 24.5, 18.0, 43.0, 36.0,\n       24.800701141357422, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0,\n       15.0, 31.0, 4.0, 25.401071548461914, 25.0, 60.0, 52.0, 44.0,\n       24.800701141357422, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0,\n       45.0, 42.0, 22.0, 19.965560913085938, 24.0, 44.0030517578125, 48.0,\n       29.0, 52.0, 19.0, 38.0, 27.0, 27.261302947998047, 33.0, 6.0, 17.0,\n       34.0, 50.0, 27.0, 20.0, 30.0, 24.800701141357422, 25.0, 25.0, 29.0,\n       11.0, 33.31815719604492, 23.0, 23.0, 28.5, 48.0, 35.0,\n       28.847219467163086, 28.847219467163086, 44.0030517578125, 36.0,\n       21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0,\n       23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, 27.261302947998047, 41.0,\n       20.0, 36.0, 16.0, 51.0, 40.654579162597656, 30.5,\n       25.979949951171875, 32.0, 24.0, 48.0, 57.0, 28.847219467163086,\n       54.0, 18.0, 28.847219467163086, 5.0, 28.847219467163086, 43.0,\n       13.0, 17.0, 29.0, 19.965560913085938, 25.0, 25.0, 18.0, 8.0, 1.0,\n       46.0, 28.847219467163086, 16.0, 7.868288516998291,\n       40.654579162597656, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0,\n       11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0,\n       6.0, 30.5, 39.640010833740234, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0,\n       38.0, 27.0, 2.0, 28.847219467163086, 25.401071548461914, 1.0,\n       28.847219467163086, 62.0, 15.0, 0.83, 28.847219467163086, 23.0,\n       18.0, 39.0, 21.0, 28.847219467163086, 32.0, 44.0030517578125, 20.0,\n       16.0, 30.0, 34.5, 17.0, 42.0, 6.937412261962891, 35.0, 28.0,\n       36.618064880371094, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0,\n       24.0, 28.847219467163086, 41.0, 21.0, 48.0, 7.868288516998291,\n       24.0, 42.0, 27.0, 31.0, 28.847219467163086, 4.0, 26.0, 47.0, 33.0,\n       47.0, 28.0, 15.0, 20.0, 19.0, 28.847219467163086, 56.0, 25.0, 33.0,\n       22.0, 28.0, 25.0, 39.0, 27.0, 19.0, 19.830495834350586, 26.0, 32.0],\n      dtype=object)"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "cleaning_pipeline = Pipeline([\n",
    "    ('imp1', imputer_1),\n",
    "    ('imp2', imputer_2),\n",
    "    ('fare_imp', ImputeFare()),\n",
    "    ('age_imp', ImputeAge()),\n",
    "])\n",
    "\n",
    "X = cleaning_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n"
    }
   ],
   "source": [
    "X = model_pipeline.fit_transform(data)\n",
    "print(sum(nan_ix))\n",
    "testdata = pd.read_csv(data_dir + 'test.csv')\n",
    "X_test = model_pipeline.fit_transform(testdata)\n",
    "y = X_test[Fare_ix]\n",
    "nan_ix = np.isnan(y.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1.0], dtype=object)"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "fim = ImputeFare()\n",
    "X1 = fim.fit_transform(X_test)\n",
    "X1[nan_ix, Fare_ix[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}